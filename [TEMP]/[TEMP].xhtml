<?xml version="1.0" encoding="utf-8"?>
<!--
                                                                                     
 h       t     t                ::       /     /                     t             / 
 h       t     t                ::      //    //                     t            // 
 h     ttttt ttttt ppppp sssss         //    //  y   y       sssss ttttt         //  
 hhhh    t     t   p   p s            //    //   y   y       s       t          //   
 h  hh   t     t   ppppp sssss       //    //    yyyyy       sssss   t         //    
 h   h   t     t   p         s  ::   /     /         y  ..       s   t    ..   /     
 h   h   t     t   p     sssss  ::   /     /     yyyyy  ..   sssss   t    ..   /     
                                                                                     
	<https://y.st./>
	Copyright © 2019 Alex Yst <mailto:copyright@y.st>

	This program is free software: you can redistribute it and/or modify
	it under the terms of the GNU General Public License as published by
	the Free Software Foundation, either version 3 of the License, or
	(at your option) any later version.

	This program is distributed in the hope that it will be useful,
	but WITHOUT ANY WARRANTY; without even the implied warranty of
	MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
	GNU General Public License for more details.

	You should have received a copy of the GNU General Public License
	along with this program. If not, see <https://www.gnu.org./licenses/>.
-->
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">
	<head>
		<base href="https://y.st./[TEMP]/[TEMP].xhtml"/>
		<title>Components of data mining &lt;https://y.st./[TEMP]/[TEMP].xhtml&gt;</title>
		<link rel="icon" type="image/png" href="/link/CC_BY-SA_4.0/y.st./icon.png"/>
		<link rel="stylesheet" type="text/css" href="/link/main.css"/>
		<script type="text/javascript" src="/script/javascript.js"/>
		<meta name="viewport" content="width=device-width"/>
	</head>
	<body>
<nav>
</nav>
		<header>
			<h1>Components of data mining</h1>
			<p>Written in <span title="Data Mining and Machine Learning">CS 4407</span> by <a href="https://y.st./">Alexand(er|ra) Yst</a>, finalised on 2019-02-13</p>
		</header>
<div style="line-height: 2;">
<div class="APA_title_page">
	<p style="
	text-align: center;
	margin-top: 50%;
	margin-bottom: 50%;
">
		Components of data mining<br/>
		Alex Yst<br/>
		CS 4407: Data Mining and Machine Learning<br/>
		Unit 2
	</p>
</div>
<p>
	The assignment instructions for this essay aren&apos;t really very clear.
	They tell us to compare three examples from <strong>*one*</strong> of the following categories: databases, statistical packages, or <abbr title="application programming interface">API</abbr>s.
	They then go on to tell us to compare our selected database, statistics package, and <abbr title="application programming interface">API</abbr>, as well as explain how they fit together within a single system.
	To do this, we&apos;d need to select one from each category, even though the instructions prior had told us to select three items from <strong>*one*</strong> category.
	It could be unclear wording in the first part, except that the database option clarifies and says we should compare a &quot;traditional&quot; database, an analytical database, <strong>*and*</strong> a non-relational database, which again points toward us choosing three items from one category.
	And to top it off, the hints as to what the grading rubric will be say to make sure to discuss all three categories.
	This lack of clarity as to what we&apos;re supposed to write about means we&apos;re not likely to meet the expectations for grading, because we can&apos;t even be sure what those expectations are.
	We&apos;ve got to just guess and hope for the best.
	I&apos;m guessing we&apos;re intended to write about one of each and explain how they can be used together in a single system, so that&apos;ll be my focus, but I&apos;ll also try to compare options just in case that&apos;s what was intended of us.
</p>
<p>
	There&apos;s also ambiguity as to what is meant by a &quot;traditional&quot; database.
	That&apos;s not really a database type.
	I&apos;m guessing what is meant is a <strong>*relational*</strong> database, not a &quot;traditional&quot; database.
	Again, given the lack of clarity, that&apos;s what I&apos;ll be going with.
</p>
<p>
	This paper is going to be a bit long.
	I&apos;m basically covering about four times what I think was intended, just to make sure I cover the things I need to.
	If you don&apos;t like reading all this, blame the ambiguity of the assignment.
	I&apos;m honestly not sure which of this stuff is intended to be part of the assignment and which isn&apos;t.
	That said, I&apos;ll try to make this as brief as I can.
</p>
<h2>Databases</h2>
<p>
	This week, we studied non-relational databases, and compared them with relational databases.
	We didn&apos;t discuss statistical databases at all though.
	So let&apos;s start out by discussion relational and non-relational databases, then move on to discuss statistical databases.
</p>
<h3>Relational databases</h3>
<p>
	For many people, when they think of a database, they think of a relational database.
	Relational databases, such as MySQL, have a number of advantages.
	Their biggest advantage is that the software that manages them keeps these databases in a coherent state.
	Every potential change to the data - whether it be an insertion, a deletion, or an update - is checked to see if it would leave the database in a valid state.
	This means data can&apos;t be put where it doesn&apos;t belong, but also means that data must be kept consistent.
	Relational databases impose a rigid structure on the data they contain, and that structure may not be violated.
	Data on one table can also relate to data on another table.
	With the right table structures, you can avoid duplicating data by moving common data elements to their own table instead of including them in each and every row (Strauch, n.d.).
</p>
<p>
	These advantages all come at a computational cost though.
	Every potential change to the database must be gone over thoroughly to ensure it doesn&apos;t put the database into an invalid state, and these checks take processing power, and thus time.
	It can also be very difficult to store data that doesn&apos;t conform to a rigid structure when you&apos;re using a relational database.
	Relational databases don&apos;t function efficiently when spread out across multiple machines, either (Strauch, n.d.).
</p>
<h3>Non-relational databases</h3>
<p>
	Non-relational databases seek to eliminate the main problems associated with relational databases.
	Their main feature is that they don&apos;t impose rigid structure on the data.
	This removes all the integrity checks relational databases must perform, speeding up insertions, deletions, and updates.
	Without the rigid structure, it can also be much easier to store items that don&apos;t have as rigid a structure as a relational database prefers to store.
	Some non-relational database options provide greats support for splitting databases across multiple machines, too (Strauch, n.d.).
	Non-relational databases are said to scale better than relational databases because of this ability to easily be split cross multiple machines.
	Without being split up, you&apos;d instead need increasingly-capable single machines (Leavitt, 2010).
</p>
<p>
	Without rigid structure, tables can&apos;t relate to one another.
	Furthermore, without rigid integrity checks performed by the database software, data can become inconsistent.
	For example, a table listing all comments by a user may list a comment not listed in the table that lists all the comments for a particular thread, for a comment by that user on that thread.
	If such consistency is required, the checks must be performed outside the database software, and instead in the application (Strauch, n.d.).
</p>
<h3>Statistical databases</h3>
<p>
	Statistical database management systems are built to support the operations required or otherwise useful for statistical analysis.
	Common database management systems supply a few of the operations needed, but not nearly all of them.
	Statistical databases don&apos;t use <abbr title="Structured Query Language">SQL</abbr>, as it&apos;s not nearly flexible enough, so they use their own query language instead.
	Data is stored in a way that preserves semantics that would be lost when using relational databases.
	Many of the other benefits are those presented by relational databases as well, such as consistency constrains and database locking (Srivastava &apos; Ngo, n.d.).
</p>
<p>
	Two major disadvantages of statistical databases come to mind.
	The main one is that these databases are so tuned to deal with statistical data that they likely don&apos;t function well for other types of data.
	As we learned this week, specialised solutions are much better than generalised solutions for the use cases they are built for, but if your use case doesn&apos;t match, you&apos;ll need a different specialised solution instead.
	Secondly, the statistical operations they provide can be instead provided by a statistical operation package transparently to the user, meaning that users can have access to these operations with any type of database, not just a statistical database (Srivastava &apos; Ngo, n.d.).
</p>
<h2>Statistical packages</h2>
<p>
	Statistical packages provide us with the tools needed to perform statistical work with our data.
	In this course, the main one we&apos;ve really looked at is R.
</p>
<h3>S and S-Plus</h3>
<p>
	S was an old statistical package originally available to educational institutions, but once it was sold to Insightful, it eventually lost popularity.
	Insightful changed the way the product was marketed it, rebranding it as S-Plus in the process, and it wasn&apos;t freely-available to educational institutions any more.
</p>
<h3>LISP-STAT</h3>
<p>
	With the advent of LISP-STAT, S-Plus kind of fell out of use.
	LISP-STAT wasn&apos;t quite the same thing, but it was close enough and was much easier and less expensive to get ahold of.
	In fact, it was free software, which meant it could even be modified to fit the needs of its users.
	LISP-STAT was embedded in the Lisp interpreter, which meant that a full programming language was available to all that used it, making it highly flexible (Leeuw, n.d.).
</p>
<h3>R</h3>
<p>
	R is a free software statistical package designed to usurp S, an older proprietary statistical package.
	It pretty much replaced S.
	Users that liked the way S worked migrated from LISP-STAT to R, getting back to having the S environment without any of the baggage of the actual S-Plus software (Leeuw, n.d.).
	R can be run interactively for quick operations, but is fully capable of running S scripts, as well (R Core Team, 2018).
	That means R can be used in an automated fashion and in combination with other tools.
</p>
<h2><abbr title="application programming interface">API</abbr>s</h2>
<p>
	Our reading assignment didn&apos;t really discuss any specific statical packages, though it did drop a few names in the various tables presented, such as <abbr title="Waikato Environment for Knowledge Analysis">Weka</abbr>, Orange, and Hadoop.
	All three of these are free software, so you don&apos;t need to worry about malicious things hidden away in the code.
	We didn&apos;t really discuss <abbr title="application programming interface">API</abbr>s this week though, so I&apos;m guessing it&apos;s not the details of the <abbr title="application programming interface">API</abbr>s we&apos;re intended to discuss, but rather the benefits and drawbacks to each package.
	After all, learning three <abbr title="application programming interface">API</abbr>s in one week so we can compare and contrast them is a bit excessive, and we&apos;d never be able to pull that off in such a limited time.
	I&apos;ll cover what these packages are very briefly;.
</p>
<h3><abbr title="Waikato Environment for Knowledge Analysis">Weka</abbr></h3>
<p>
	<abbr title="Waikato Environment for Knowledge Analysis">Weka</abbr> is intended as a collection of algorithms used for data mining (The University of Waikato, n.d.).
	<abbr title="Waikato Environment for Knowledge Analysis">Weka</abbr> and hadoop serve very different purposes, and could be used together.
	Hadoop would take care of storage and distributed processing, while <abbr title="Waikato Environment for Knowledge Analysis">Weka</abbr> would supply the algorithms used in said processing.
</p>
<h3>Orange</h3>
<p>
	Orange is used for data mining, but more interestingly, is used for data visualisation (University of Ljubljana, n.d.).
	It&apos;s also got a plug-in system that allows developers to extend the functionality of the product.
	Though I&apos;ve never had the chance to actually use the tool, it seems like the data visualisation would come in handy for understanding the patterns present in the data you&apos;re working with.
	As we learned last week, R offers the option to visualise data too, but this doesn&apos;t seem to be a strength <abbr title="Waikato Environment for Knowledge Analysis">Weka</abbr> has.
	Again, Orange seems like a good tool to use in combination with Hadoop, but there&apos;s no need to combine it with <abbr title="Waikato Environment for Knowledge Analysis">Weka</abbr>, as Orange and <abbr title="Waikato Environment for Knowledge Analysis">Weka</abbr> fill similar roles.
</p>
<h3>Hadoop</h3>
<p>
	Apache Hadoop is software used to set up distributed filesystems (The Apache Software Foundation, n.d.).
	It also facilitates the breaking down of data so it can be processed in a distributed manner as well.
	Unlike <abbr title="Waikato Environment for Knowledge Analysis">Weka</abbr> and orange, Hadoop is able to store large quantities of data in a fault-tolerant way.
	If one server goes down, that same data can be found on other servers in the cluster (or in another data centre, as Hadoop can likewise operate across servers separated by vast distances).
</p>
<h2>A complete system</h2>
<p>
	Using one tool from each of these three categories, it&apos;s easy to see how a complete system could be used.
	For example, we could use Hadoop to store a database.
	This database could be a non-relational one, allowing all sorts of unstructured data to be kept without hassle.
	Hadoop would take care of both the distribution of the data across servers as well as the redundancy needed to avoid most data loss.
	(Some data loss is still likely due to the nature of non-relational databases, but that&apos;s data that failed to make it into the database, not data that was lost after having been successfully saved.)
	When we go to analyse our data, we could use one of the statistical packages, such as R or LISP-STAT, or one of the other <abbr title="application programming interface">API</abbr>s, such as those provided by Orange or <abbr title="Waikato Environment for Knowledge Analysis">Weka</abbr>.
	If we wanted to visualise the data, Orange or R would probably be good choices.
</p>
<div class="APA_references" style="margin-left: 4em;text-indent: -4em;">
	<h2>References:</h2>
	<p>
		The Apache Software Foundation. (n.d.). Apache Hadoop. Retrieved from <a href="https://hadoop.apache.org/"><code>https://hadoop.apache.org/</code></a>
	</p>
	<p>
		Leavitt, N. (2010, January 26). Will NoSQL Databases Live Up to Their Promise? Retrieved from <a href="http://leavcom.com/pdf/NoSQL.pdf"><code>http://leavcom.com/pdf/NoSQL.pdf</code></a>
	</p>
	<p>
		Leeuw, J. D. (n.d.). STATISTICAL SOFTWARE - OVERVIEW. Retrieved from <a href="http://gifi.stat.ucla.edu/janspubs/2009/reports/deleeuw_R_09a.pdf"><code>http://gifi.stat.ucla.edu/janspubs/2009/reports/deleeuw_R_09a.pdf</code></a>
	</p>
	<p>
		R Core Team. (2018, December 20). An Introduction to R: 14 OS facilities. Retrieved from <a href="https://cran.r-project.org/doc/manuals/R-intro.html#OS-facilities"><code>https://cran.r-project.org/doc/manuals/R-intro.html#OS-facilities</code></a>
	</p>
	<p>
		Srivastava, J., &amp; Ngo, H. J. (n.d.). Statistical Databases. Retrieved from <a href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.128.4820&amp;rep=rep1&amp;type=pdf"><code>https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.128.4820&amp;rep=rep1&amp;type=pdf</code></a>
	</p>
	<p>
		Strauch, C. (n.d.). NoSQL Databases. Retrieved from <a href="https://christof-strauch.de/nosqldbs.pdf"><code>https://christof-strauch.de/nosqldbs.pdf</code></a>
	</p>
	<p>
		University of Ljubljana. (n.d.). Orange - Data Mining Fruitful &amp; Fun. Retrieved from <a href="https://orange.biolab.si/"><code>https://orange.biolab.si/</code></a>
	</p>
	<p>
		The University of Waikato. (n.d.). Weka 3 - Data Mining with Open Source Machine Learning Software in Java. Retrieved from <a href="https://www.cs.waikato.ac.nz/ml/weka/"><code>https://www.cs.waikato.ac.nz/ml/weka/</code></a>
	</p>
</div>
</div>
<section id="Unit2">
	<h2>Unit 2</h2>
	<p>
		The reading assignments for the week are as follows:
	</p>
	<ul>
		<li>
			<a href="https://secure.php.net/manual/en/install.php">PHP: Installation and Configuration - Manual</a>
		</li>
		<li>
			<a href="https://secure.php.net/manual/en/install.unix.apache2.php">PHP: Apache 2.x on Unix systems - Manual</a>
		</li>
		<li>
			<a href="https://www.w3schools.com/php/default.asp">PHP 5 Tutorial</a>
		</li>
	</ul>
	<p>
		It seems this week is mostly about installing Web server software from source.
		I find it a bit amusing that we&apos;ve waited until a 3000-level course to cover that.
		It&apos;s a good skill to have.
		I actually got my start on the Web on an OS X machine.
		It came with Apache and <abbr title="PHP: Hypertext Preprocessor">PHP</abbr> bundled and integrated with the operating system.
		However, Apple hardware is expensive, so I had a really old matching that Apple didn&apos;t support with newer operating system versions.
		Apache and <abbr title="PHP: Hypertext Preprocessor">PHP</abbr> were really old.
		Once I figured out how to even get my website accessible from outside my home, using my machine as the Web host, I started trying to build a cool and interactive website out of <abbr title="PHP: Hypertext Preprocessor">PHP</abbr>.
	</p>
	<p>
		I invented pseudo-namespaces, fearing that if someone used my code, my function names would clash with theirs.
		I basically just prefixed all my function names with the domain name of my website followed with two underscores, with the dot converted to an underscore as well.
		Even without having learned about namespaces, I understood their value and importance.
		I later learned my version of <abbr title="PHP: Hypertext Preprocessor">PHP</abbr> was painfully old, and had to learn how to install a newer version.
		It was tied so heavily into Apache though that I needed to upgrade Apache as well.
		Both <abbr title="PHP: Hypertext Preprocessor">PHP</abbr> and Apache had to be installed from source code.
		And with the newer version of Apache, I lost the <abbr title="operating system">OS</abbr> integration, as Apple had specifically tied that version of Apache to the <abbr title="operating system">OS</abbr>.
		If I recall, it took days or weeks to figure out how to get everything installed correctly.
		I had no idea what I was doing, and had to learn how to use Apple&apos;s proprietary development tools to compile, as that was necessary at the time.
		It might even be necessary now, but I wouldn&apos;t know.
		With the upgrade though, I had real namespaces, and was able to remove my ugly prefixes in favour of doing things the right way (<code>net\example\function_name()</code> instead of <code>example_net__function_name()</code>).
	</p>
	<p>
		Later, my computer died on me.
		My pibling gave me a new laptop (well, new to me and much newer than my old machine, but still very old).
		It ran Windows though, and Windows and I have <strong>*never*</strong> gotten along.
		There&apos;s a reason I was on an ancient OS X machine when I could have afforded a newish Windows machine for about the same price.
		So I looked into how to install OS X on non-Apple hardware.
		It turns out it&apos;s very possible, but also illegal due to language in the OS X license agreement.
		Not wanting to break the law, I looked into alternative systems.
		Anything had to be better than Windows, right?
		<strong>*Anything*.</strong>
		Even if it wasn&apos;t as good as OS X, I&apos;d have a better chance of getting by with whatever I ended up with than I would sticking with the copy of Windows already on the machine.
		I&apos;d heard about something called &quot;Linux&quot;, but I wasn&apos;t sure how usable it was.
		So I looked into that first.
	</p>
	<p>
		I found Linux wasn&apos;t a single operating system, but a multitude of operating systems that shared a similar codebase.
		But the developers of these systems <strong>*wanted*</strong> me to install their system.
		Apple was telling me to go away if I wasn&apos;t going to buy not only their operating system but their hardware as well.
		The Linux communities didn&apos;t care what hardware I used though.
		I agonised over the decision of what system to install.
		I don&apos;t recall how long it took me to decide.
		With so many options, how do I know which is right for me?
		I ended up choosing Ubuntu 12.04, which had come out that month, if I recall.
		It seemed popular, compared to other Linux versions.
		Maybe people knew what they were doing and chose it because it was good.
	</p>
	<p>
		The interface was a bit strange, but it was usable.I found Apache and <abbr title="PHP: Hypertext Preprocessor">PHP</abbr> were in the software repositories.
		Installing them took almost no effort.
		I greatly appreciated that these tools were cross-platform.
		I was learning to use a new system, but I didn&apos;t need to learn new server software right away.
		That was awesome.
		I spent about a week on Ubuntu, if I recall, but then I had an epiphany: Canonical never charged me for Ubuntu.
		Most of the other distribution vendors weren&apos;t charging either.
		All it cost me was the price of a <abbr title="digital versatile disc">DVD</abbr> to burn the system on.
		I could afford to try out other systems!
		And try them out I did.
		I tried Debian, I tried Mint.
		Mint was kind of cool at the time.
		I stuck with it a while, and later went to Xubuntu, a variant of Ubuntu produced by the same Canonical, but with a better desktop interface.
		For a class, I tried out Fedora as well, though it was never my cup of tea, and now I&apos;m back on Debian for licensing reasons.
		Because I&apos;ve learned to care about licensing.
		No matter where I drift though, <abbr title="PHP: Hypertext Preprocessor">PHP</abbr> and Apache follow me.
		They&apos;re free software, so the source code is readily available.
		And when the source code is available, there will be people that want to port it to their system.
		Porting to Linux once takes care of running it on all Linux distributions, but if I were ever to switch to a drastically different system, such as <abbr title="Berkeley Software Distribution">BSD</abbr>, <abbr title="PHP: Hypertext Preprocessor">PHP</abbr> and Apache have already beaten me there, too.
		While I might not always choose them, they&apos;ll always here with me for me to choose if I want to.
	</p>
	<p>
		I admit I&apos;ve gone soft, and no longer compile my own Web server software.
		I still know how to though, so the pages on doing that were just review.
		The <abbr title="PHP: Hypertext Preprocessor">PHP</abbr>7 tutorial was of no help to me though.
		I use <abbr title="PHP: Hypertext Preprocessor">PHP</abbr>7 on a daily basis.
		I&apos;m very familiar with the language and its syntax.
		I&apos;ve got to look up a function name every once in a while, when I&apos;m doing something I don&apos;t usually do, but a tutorial&apos;s not going to help me remember the names of functions I hardly ever use, or even ones I&apos;ve never used before.
	</p>
	<p>
		For the main assignment for the week, we were to take screenshots and paste them into a word-processing document.
		That&apos;s a format to transfer screenshots in, but I followed those instructions to the letter just the same.
		Alongside the uploaded word-processing document though, I submitted my work in a better format: simply uploading the images and using <code>&lt;img/&quot;</code> tags to display them as a part of the page.
		That way, other students don&apos;t have to download them as a separate attachment, then open them up in a word-processor.
		I mean, seriously, what a pain in the neck for no good reason, right?
		I did have to doctor one of the screenshots a bit though.
		The assignment said to screenshot the output of <code>phpinfo()</code> in a screenshot, up to the last <code>/etc</code> &quot;command (sic)&quot;.
		Between the top bar of the website and the bottom bar, too much space was eaten up, and that much couldn&apos;t be displayed at once without a bigger monitor than my laptop has.
		Firefox allows you to modify the code of pages you look at though.
		SO I deleted the top and bottom bar, freeing up enough space to get all the requested output captured.
	</p>
</section>
<section id="Unit2">
	<h2>Unit 2</h2>
	<p>
		The reading assignment for the week is as follows:
	</p>
	<ul>
		<li>
			<a href="https://christof-strauch.de/nosqldbs.pdf">NoSQL Databases - nosqldbs.pdf</a>
		</li>
		<li>
			Chapters eight through fourteen of <a href="https://cran.r-project.org/doc/manuals/R-intro.html">An Introduction to R</a>
		</li>
		<li>
			<a href="https://my.uopeople.edu/brokenfile.php#/290113/user/draft/702716931/An%20Overview%20of%20Data%20Warehousing%20and%20OLAP%20Technology.pdf"><em>(No file data)</em></a>
		</li>
		<li>
			<a href="https://my.uopeople.edu/pluginfile.php/389189/mod_book/chapter/179438/Data%20mining%20tools.pdf">WIDM-24_LR - Data mining tools.pdf</a>
		</li>
		<li>
			<a href="https://thesai.org/Downloads/SpecialIssueNo3/Paper%204-A%20Comparison%20Study%20between%20Data%20Mining%20Tools%20over%20some%20Classification%20Methods.pdf">A Comparison Study between Data Mining Tools over some Classification Methods - Paper 4-A Comparison Study between Data Mining Tools over some Classification Methods.pdf</a>
		</li>
		<li>
			<a href="http://gifi.stat.ucla.edu/janspubs/2009/reports/deleeuw_R_09a.pdf">deleeuw_R_09a.pdf</a>
		</li>
		<li>
			<a href="http://leavcom.com/pdf/NoSQL.pdf">NoSQL.pdf</a>
		</li>
		<li>
			<a href="http://melekirmak.com/trepon/images/260220121521451.pdf">Trepon Images 260220121521451 Pdf için bir şey bulunamadı</a>
		</li>
		<li>
			<a href="http://web.ist.utl.pt/~ist13085/fcsh/sio/casos/BI-Tech2.pdf">Técnico Lisboa - Página Não Encontrada / Page Not Found</a>
		</li>
	</ul>
	<p>
		One of these is a link to the university&apos;s own <code>/brokenfile.php</code> file.
		It&apos;s not even a redirect from an actual broken file either, I checked.
		The <abbr title="Uniform Resource Identifier">URI</abbr> provided in the hyperlink is that of the broken file error page.
		AN error page, by the way, that doesn&apos;t actually display any sort of error message.
		It just refuses to send any data.
		To add to that, two of the links are outdated and lead to <code>404</code> pages.
	</p>
	<p>
		I&apos;d thought that NoSQL was a particular database, such as MySQL or SQLite.
		I was guessing that with a name like that, it probably didn&apos;t use a structured query language, but at the same time, the fact that it even mentions <abbr title="Structured Query Language">SQL</abbr> made me think it likely tries to emulate databases that do use <abbr title="Structured Query Language">SQL</abbr> or something.
		It turns out I was way off.
		NoSQL isn&apos;t a product at all, but instead a term coined to refer to non-relational databases.
		Most if not all relational database software options use a form of <abbr title="Structured Query Language">SQL</abbr> to allow users to tell it what to store and retrieve, so NoSQL refers to the fact that a given database doesn&apos;t have that.
		It&apos;s a misleading term, as while <abbr title="Structured Query Language">SQL</abbr> and relational databases are often used together, they&apos;re actually very separate concepts.
		&quot;Relational&quot; refers to the fact that the database tables may relate their data to data on other tables, while <abbr title="Structured Query Language">SQL</abbr> is the language (which admittedly is usually not implemented according to the standard) used to speak with the database software.
		I could build a relational database software that doesn&apos;t use any form of <abbr title="Structured Query Language">SQL</abbr>, yet it somehow wouldn&apos;t be considered a NoSQL database.
		In other words, its a complete misnomer.
	</p>
	<p>
		Non-relational databases are useful because they handle very efficiently the types of data relational databases are particularly bad at handling.
		Relational databases need rigid structure.
		Otherwise, you can&apos;t figure out what data relates to what other data in another table.
		Without relations getting in the way, you can store whatever you want in a non-relational database.
		Examples given in the text include emails, word-processing documents, and media.
		Some non-relational databases can also be distributed across multiple machines, something that relational databases don&apos;t seem to handle well.
		Non-relational databases also run faster, due to less happening when queries are run.
		Relational databases have to check to see if an update to the data would break the database&apos;s rules, and if it won&apos;t, they sometimes have to make further changes to other parts of the data that are implied by the change made by the query.
		A non-relational database has neither of these added side-effects of data update.
	</p>
	<p>
		Non-relational databases do have their drawbacks though.
		Without the <abbr title="Structured Query Language">SQL</abbr> provided by relational databases, non-relational databases rely on directly programming queries through the database&apos;s <abbr title="application programming interface">API</abbr>.
		Supposedly, this is more difficult, though I have difficulty with <abbr title="Structured Query Language">SQL</abbr>.
		I think I might do better with direct <abbr title="application programming interface">API</abbr> calls.
		You could claim that with <abbr title="Structured Query Language">SQL</abbr>, you have a unified language with with to communicate with all relational databases, but that would be a lie.
		No one follows the <abbr title="Structured Query Language">SQL</abbr> standard, so each database vendor provides their own non-standard dialect of <abbr title="Structured Query Language">SQL</abbr>.
		Whether you&apos;re learning a new <abbr title="Structured Query Language">SQL</abbr> dialect or new <abbr title="application programming interface">API</abbr> functions, you&apos;re not able to jump right from one database software to another.
		Due to the lack of rule-enforcement, non-relational databases are also easier to enter inconsistent or otherwise invalid data into, which can be problematic.
		Likewise, with non-relational databases only gaining popularity recently, there&apos;s a lack of tools for administering them at this time.
	</p>
	<p>
		The next article I read was about which statistical tools replaced which other statistical tools and when.
		It was more of a history lesson than anything useful.
		It did bring up that the field of science is moving toward open source as a means of reproducibility.
		That&apos;s good to hear.
		With open source tools, we can better learn how the tools themselves function, and thus how the data we use the tools on behaves.
		And isn&apos;t that what science is all about?
		Really, closed source tools have no place in science or any sort of school.
		They just hide away their implementations so you can&apos;t learn from them, making them counterproductive in such environments.
	</p>
	<p>
		I didn&apos;t really understand the paper on the study comparing data-mining tools.
		It didn&apos;t help that the table data wasn&apos;t displaying correctly.
		I think it&apos;s a bug in Firefox; I&apos;ve had that issue with other <abbr title="Portable Document Format">PDF</abbr>s on the Web as well.
	</p>
	<p>
		The next paper I read both reiterated the history of data-mining software and broke down what to look for when choosing data-mining software from the multitude of options.
		Again, I don&apos;t think such history lessons are useful, but the point-by-point discussion of what features to look for had value.
		Of course, if you can&apos;t trust your tools, you can&apos;t trust their results, so licensing and source code availability will always be the most important thing to consider when I choose my software.
		The wrong license is a deal-breaker for me.
		The paper did discuss licensing and its importance, which was good to see.
		Once you rule out the badly-licensed software, the other points can be used to figure out which option best suits your specific project.
		Different data-mining programs cater to different groups of users and different use cases.
		Sparsity of the data, how many dimensions it has, and whether or not you&apos;re trying to cluster it are all things to think about.
		You also need to decide whether your task is better suited to supervised or unsupervised learning.
		Do you have a training set to work with that already has an answer key?
		You also need to decide whether you want a command line interface or a graphical interface.
		Less techy people will want a <abbr title="graphical user interface">GUI</abbr>, but people who know how to work a computer well will appreciate the ease of automation that comes with a command line interface.
	</p>
	<p>
		It seems a number of open and widely-implemented data exchange formats are available for importing and exporting data.
		These should of course be used ahead of proprietary formats.
		The major problem with proprietary formats is that you can&apos;t switch tools and keep your data.
		You might want to replace your software with better software from another vendor at some point, but even if you don&apos;t, different tools work better for different use cases.
		You might therefore want to use the same data with multiple tools.
		Open formats make this possible.
		You also need to look at what system you plan to use your tools with when deciding which tools to choose.
		That said, if you choose the open source tools as I recommended, it&apos;s very likely your platform will be supported.
		People have a tendency to port open source tools to their platform, then make the necessary code changes available to everyone, providing support for that project on that operating system available to the public.
		This is different from proprietary tools, in which you have to depend on the vendor themselves to provide support for a given platform (and often, proprietary vendors don&apos;t bother to support very many platforms).
	</p>
	<p>
		The 149-page paper begins by telling us that the NoSQL term originally referred to relational databases that lacked <abbr title="Structured Query Language">SQL</abbr>.
		That&apos;s a much more intuitive and reasonable usage of the term.
		However, the term later degraded to instead refer to non-relational databases, which is a confusing use of the term, as I discussed above.
		Seriously, they should have coined their own term instead of hijacking a term already in use.
	</p>
	<p>
		Most of the benefits of non-relational databases discussed by this paper were already covered by the 3-page paper, but the longer paper also brought up that servers can be brought offline or even crash without taking the whole database down with them.
		Obviously, the data stored on that particular server becomes unavailable, but the rest of the data on the other serves remains accessible.
	</p>
	<p>
		It also talks about how one-size-fits-all database solutions are wrong.
		In general, one-size-fits-all solutions for <strong>*anything*</strong> are wrong.
		There are notable exceptions to this, but if you think your solution fits every use case, you&apos;ve probably forgotten to consider several use cases.
		It&apos;s also brought up that one-size-fits-all solutions tend not to perform as quickly or as efficiently as solutions tailored to the actual use case you&apos;re working with.
	</p>
	<p>
		A great point is made too about abstracting away a database&apos;s distributed nature.
		If applications don&apos;t realise the database is distributed, they cannot make the correct decision based on that information.
		Network latency and downed servers cannot be abstracted away, so both can appear as missing data to the application if the application isn&apos;t made aware that it&apos;s not speaking with a single database instance on a single server.
	</p>
	<p>
		One issue I had with this paper is that it says we should do everything in <abbr title="random-access memory">RAM</abbr> and have zero <abbr title="input/output">I/O</abbr>.
		Keeping everything in memory is one thing.
		Assuming you have enough <abbr title="random-access memory">RAM</abbr>, it&apos;ll speed things up considerably.
		However, you still need disk writes.
		If the power goes out or your system crashes, you&apos;ll want a semi-recent copy of the data to read back into memory once you&apos;re back online.
		You might not want to write to disk with every change, but you will want to write changes to disk periodically.
	</p>
	<p>
		The paper also discusses that while non-relational databases may be developer-friendly, they&apos;re not as administrator-friendly.
		They lack the sort of query language that makes ad-hoc access of data easy.
		With only the <abbr title="application programming interface">API</abbr> to update or view data, administrators have to write a program each time they want to make a change to the data or even just check on existing data.
		Of course, this could easily be accounted for if developers wrote some sort of administration panel for the administrators to manage the database with.
		However, the paper goes on to explain that access of data in a distributed system is more difficult too.
		I don&apos;t really have a solution to that problem.
		Exporting data from a distributed database also comes with difficulties.
	</p>
	<p>
		I ended up not being able to get back to that 441-page document from last week.
		I thought life would just sort of stop for my during the week of the surgery, and I&apos;d have all the time in the world for coursework.
		That didn&apos;t happen.
		I still had things I needed to get done, and while I did have the week off from work, I also slept a lot more.
		Part of that was because I needed more rest to heal properly, but another part is that I usually don&apos;t get enough sleep because I&apos;m far too busy.
		For the first time in a long while, I actually got the sleep I needed.
		I also found myself too tired to get any coursework done unless I kept my body moving.
		I had to get out and take a walk each day, or I didn&apos;t feel well enough to even attempt any reading assignments.
		And those walks took time too.
	</p>
	<p>
		Research for the paper this week also took longer than expected.
		Finding open-access journals is difficult, and we needed peer-reviewed journals for our papers this week.
		The assignment instructions recommended checking one of the libraries that lends their resources to this school, but those sites don&apos;t allow outsiders to view their contents.
		This presents two major problems.
		First of all, search engines can&apos;t get in there.
		These libraries have internal search features, but they rather suck.
		I can spend hours trying to find something in there, and turn up empty-handed.
		Without open access, regular search engines can&apos;t get in, and without using an actual search engine, you can&apos;t reasonably find what you need.
		Secondly, without open access, it doesn&apos;t matter what I cite anyway, because no one reading my paper will be able to check my sources for validity or further information.
		Citing pages that exist only in walled gardens doesn&apos;t do a lick of good.
		That makes the university&apos;s partner libraries utterly and completely useless.
		So I had to look elsewhere.
		I never did find any published journal sources to describe the specific analytical packages we were told to research for our papers, either.
		I ended up having to use the main websites for these projects to get a feel for them.
		In my defence though, we were told to use at least one journal resource, but not required to make all our sources come from journals.
	</p>
	<p>
		It&apos;s also worth noting that such journal sources themselves are often incredibly bias.
		I&apos;m not sure how bad it is in the tech industry, but the medical industry in the United States is completely corrupt.
		In the medical industry, good medical science often gets swept under the rug if it&apos;s not profitable.
		If it&apos;s not going to make some corporation rich, big pharmaceutical companies will often make sure word doesn&apos;t get out, even to the point of threatening doctors and scientists that would otherwise try to bring it to light.
		And many drugs aren&apos;t actually anywhere near as effective as they&apos;re claimed to be, they are just in use because they make the pharmaceutical companies money.
		These money-makers are what gets published, not the things that actually work best.
		It wouldn&apos;t surprise me if the tech industry suffered similar issues.
		The fact that information comes from published journals doesn&apos;t actually make it any more valid than information from other sources, and in fact often makes the information <strong>*less*</strong> valid.
		There&apos;s a reason I don&apos;t often cite published journals except for assignments that specifically request it.
	</p>
	<p>
		Anyway, I found the reading material didn&apos;t even mention much of what was on the essay assignment and absolutely none of what was on the discussion assignment was mentioned.
		Normally, I focus on trying to complete the reading material first, or at least a good chunk of it, before moving on to the other assignments.
		That way, I&apos;m better prepared for them.
		I see that&apos;s not going to work in this course.
		I need to work on the discussion assignment and written assignment first.
		Then, in the time remaining, I need to read as much as I can from the reading assignment.
		Starting next week, that&apos;s the approach I&apos;ll take.
	</p>
</section>
		<hr/>
		<p>
			Copyright © 2019 Alex Yst;
			You may modify and/or redistribute this document under the terms of the <a rel="license" href="/license/gpl-3.0-standalone.xhtml"><abbr title="GNU&apos;s Not Unix">GNU</abbr> <abbr title="General Public License version Three or later">GPLv3+</abbr></a>.
			If for some reason you would prefer to modify and/or distribute this document under other free copyleft terms, please ask me via email.
			My address is in the source comments near the top of this document.
			This license also applies to embedded content such as images.
			For more information on that, see <a href="/en/a/licensing.xhtml">licensing</a>.
		</p>
		<p>
			<abbr title="World Wide Web Consortium">W3C</abbr> standards are important.
			This document conforms to the <a href="https://validator.w3.org./nu/?doc=https%3A%2F%2Fy.st.%2F%5BTEMP%5D%2F%5BTEMP%5D.xhtml"><abbr title="Extensible Hypertext Markup Language">XHTML</abbr> 5.2</a> specification and uses style sheets that conform to the <a href="http://jigsaw.w3.org./css-validator/validator?uri=https%3A%2F%2Fy.st.%2F%5BTEMP%5D%2F%5BTEMP%5D.xhtml"><abbr title="Cascading Style Sheets">CSS</abbr>3</a> specification.
		</p>
	</body>
</html>

