<?xml version="1.0" encoding="utf-8"?>
<!--
                                                                                     
 h       t     t                ::       /     /                     t             / 
 h       t     t                ::      //    //                     t            // 
 h     ttttt ttttt ppppp sssss         //    //  y   y       sssss ttttt         //  
 hhhh    t     t   p   p s            //    //   y   y       s       t          //   
 h  hh   t     t   ppppp sssss       //    //    yyyyy       sssss   t         //    
 h   h   t     t   p         s  ::   /     /         y  ..       s   t    ..   /     
 h   h   t     t   p     sssss  ::   /     /     yyyyy  ..   sssss   t    ..   /     
                                                                                     
	<https://y.st./>
	Copyright © 2020 Alex Yst <mailto:copyright@y.st>

	This program is free software: you can redistribute it and/or modify
	it under the terms of the GNU General Public License as published by
	the Free Software Foundation, either version 3 of the License, or
	(at your option) any later version.

	This program is distributed in the hope that it will be useful,
	but WITHOUT ANY WARRANTY; without even the implied warranty of
	MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
	GNU General Public License for more details.

	You should have received a copy of the GNU General Public License
	along with this program. If not, see <https://www.gnu.org./licenses/>.
-->
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">
	<head>
		<base href="https://y.st./[TEMP]/[TEMP].xhtml"/>
		<title>Learning Journal &lt;https://y.st./[TEMP]/[TEMP].xhtml&gt;</title>
		<link rel="icon" type="image/png" href="/link/CC_BY-SA_4.0/y.st./icon.png"/>
		<link rel="stylesheet" type="text/css" href="/link/main.css"/>
		<script type="text/javascript" src="/script/javascript.js"/>
		<meta name="viewport" content="width=device-width"/>
	</head>
	<body>
<nav>
</nav>
		<header>
			<h1>Learning Journal</h1>
			<p>CS 3304: Analysis of Algorithms</p>
		</header>
<section id="Unit1">
	<h2>Unit 1</h2>
	<p>
		The reading assignment for the seek was as follows:
	</p>
	<ul>
		<li>
			<a href="https://discrete.gr/complexity/">A Gentle Introduction to Algorithm Complexity Analysis</a>
		</li>
		<li>
			Chapters Three, Seven, Nine, and Fourteen from <a href="https://people.cs.vt.edu/~shaffer/Book/C++3e20100119.pdf">C++3e20100119.pdf</a>
		</li>
		<li>
			<a href="https://jeffe.cs.illinois.edu/teaching/algorithms/notes/99-recurrences.pdf">99-recurrences.pdf</a>
		</li>
		<li>
			<a href="https://my.uopeople.edu/pluginfile.php/644416/mod_book/chapter/219106/algo_ch4_recurrences.pdf">Microsoft PowerPoint - algo_ch4_recurrences - algo_ch4_recurrences.pdf</a>
		</li>
		<li>
			<a href="https://users.cs.duke.edu/~reif/courses/alglectures/skiena.lectures/lecture3.pdf">lecture3.dvi - lecture3.pdf</a>
		</li>
		<li>
			<a href="https://my.uopeople.edu/pluginfile.php/644416/mod_book/chapter/219106/chapter03-algointro.pdf">chapter03-algointro.pdf</a>
		</li>
		<li>
			<a href="https://cgi.csc.liv.ac.uk/~ped/teachadmin/algor/algor.html">Algorithm Design Paradigms - Overview</a>
		</li>
		<li>
			<a href="https://www.cs.auckland.ac.nz/software/AlgAnim/alg_anim.html">Animated Algorithms</a>
		</li>
	</ul>
	<p>
		I was quite shocked to read that there will be group projects in this course.
		I&apos;m not looking forward to that.
		As of late, I&apos;ve barely had the time to get my assignments completed and submitted at all.
		Adding group work to the mix is going to make this immensely more difficult.
		How are we to coordinate with our group members in a timely fashion?
		The only way I can think to reach group members is via email, but many people don&apos;t check their email often enough to substitute for real-time conversation.
		Personally, I&apos;d be fine with using <abbr title="Internet Relay Chat">IRC</abbr> for real-time communication, but I&apos;m not sure everyone in the course is even familiar with <abbr title="Internet Relay Chat">IRC</abbr>.
		I imagine some students will want to use the web chat feature of certain social media sites, but most of the big ones won&apos;t even let me register an account, so that won&apos;t work.
		This doesn&apos;t bode well, and I&apos;m not looking forward to trying to make this work.
		It&apos;d be easier if we were an in-person class, y&apos;know?
		Then we could work on group projects face-to-face.
	</p>
	<p>
		Aside from the reading assignment and this learning journal assignment, the only work for the week was the discussion assignment.
		There, we brute force, branch-and-bounds algorithms, and asymptotic complexities.
		I think I might have read about branch-and-bounds algorithms in another course, but I&apos;m not sure.
		If I did, I don&apos;t really remember them well, so this was good review for me.
		Brut force is so simple that there&apos;s really no forgetting it.
		I usually try to do things without resorting to brute force, but it&apos;s a tool that I do use against problems when I can&apos;t think of a better way.
		Often, when I use brute force as a last resort, it takes so long to finish that in the hours it&apos;s running, I come up with something much faster, then interrupt the brute force script and write the better script to run instead.
		As for asymptotic complexities, I know I learned big oh, big theta, and big omega notation, but I don&apos;t recall small oh and small omega notation.
		Also, I feel like the textbook from this course explained all the notations better than the one in the other course, so I understand the differences better than before.
	</p>
	<p>
		I still don&apos;t really get why asymptotic complexities are done the way they are though.
		You throw out less-significant information such as constants.
		In other words, you throw out perfectly-good information that is known about run times.
		That gives you less accurate information with which to estimate how long it&apos;ll take for algorithms to run.
		This information is less impactful than the information you keep, but it&apos;s still useful in, for example, as a tie-breaker between algorithms with similar run times.
		2x + 4 and 2x + 504 both have an asymptotic complexity of Θ(x), for example, even though the second one has much more overhead, even if that overhead isn&apos;t changed based on input size.
	</p>
	<p>
		The reading assignment also covered several terms I&apos;m already well familiar with.
		Recursion was one of the main themes.
		Recursion is one of those things that&apos;s really powerful, but that I almost always think is the wrong tool for the job.
		At times, it makes the functionality of written code more obvious to the reader.
		Other times (often with huge overlap with the previous cases), it makes seemingly-unsolvable problems a piece of cake to deal with.
		But when used unnecessarily, it seems like a rather heavy hammer for a small nail.
		I&apos;ve gotten a pretty good feel for when using it&apos;s right though.
		If I can&apos;t come up with  non-recursive solution and it feels like I should be able to, I&apos;ve usually overlooked something big, and my code is needlessly complex.
		I suppose recursive programming functions are bit more touchy than recursive mathematical functions, and we&apos;re dealing with the latter so far in this course.
		Still, the idea of recursion is the same in both cases, and it&apos;s just as powerful in both.
	</p>
</section>
<section id="Unit2">
	<h2>Unit 2</h2>
	<p>
		The reading assignment for the week was as follows:
	</p>
	<ul>
		<li>
			Chapter fifteen of <a href="https://people.cs.vt.edu/~shaffer/Book/C++3e20100119.pdf">C++3e20100119.pdf</a>
		</li>
		<li>
			<a href="https://people.eecs.berkeley.edu/~vazirani/algorithms/chap2.pdf">chap2.pdf</a>
		</li>
		<li>
			<a href="http://videolectures.net/mit6046jf05_leiserson_lec13/">Lecture 13: Amortized Algorithms, Table Doubling, Potential Method - VideoLectures.NET</a>
		</li>
	</ul>
	<p>
		This week was rather frustrating.
		First, the the discussion assignment.
		I work weekends.
		My days off from work are near the end of the unit each week.
		If I&apos;m lucky, I can get the reading assignment done before then, but often times, I have to get the reading finished in the last couple days of the unit.
		The discussion assignment, of course, needs to be done long before that.
		We&apos;re also not allowed to know what the reading assignment for the next week will be, meaning that I can&apos;t simply read ahead when I can.
		This was one of those weeks that I had to complete the discussion assignment practically blind.
		Oddly enough, the written assignment for the week was a breeze, even if I had to only rely on prior knowledge.
		If the discussion assignment and written assignment had been flipped, I&apos;d&apos;ve done quite well this week.
		Secondly, there was the video lecture.
		The website hosting the video relies on Adobe Flash to provide video playback, which means I couldn&apos;t watch the lecture.
		All I could see was an error message.
		It&apos;d&apos;ve been nice to have a transcript instead of just a video.
		Even if they didn&apos;t think about people without Flash, some people, myself included, learn better when able to read instead of listen.
	</p>
	<p>
		I&apos;m having some trouble grasping what the master theorem is trying to convey to us.
		I ended up having to write up my discussion post before I&apos;d even gotten a chance to read about the master theorem, which resulted in an incredibly-ill-informed submission, but even after reading about it, I didn&apos;t really understand how to use it.
		I would have done better, but probably not by much.
		I should read up on it more when I have time, and see if I can find any examples of how to put it into practice.
		Only one student replied to my post, and they were rather rude about it, pretty much telling me that they expected a better post from me.
		That&apos;s what happens when I&apos;ve got less than a week to complete a discussion post on a topic I&apos;m not familiar with and haven&apos;t had a single day off to actually sit down with the material though.
	</p>
	<p>
		For the written assignment, we focused on justifying a divide-and-conquer approach to solving our choice of one of three situations.
		One of them was binary search, which is a classic divide-and-conquer situation.
		I&apos;m sort of surprised the assignment didn&apos;t tell us to justify a divide-and-conquer approach to searching in general and have us come up with binary search as a way to implement it.
		I mean, if you refer to binary search specifically, there&apos;s no way to solve the problem <strong>*without*</strong> a divide-and-conquer approach.
		I mean, the problem&apos;s definition then <strong>*necessarily involves*</strong> division.
		There&apos;s really no dispute over whether this problem is well-suited to a divide-and-conquer approach.
		I guess that means I chose the low-hanging fruit.
		I really needed an easy assignment though, given my rough week - not only rough in terms of school assignments, but other life matters as well.
	</p>
</section>
<section id="Unit3">
	<h2>Unit 3</h2>
	<p>
		The reading assignment for the week was as follows:
	</p>
	<ul>
		<li>
			Sections 11.1 through 11.3 of <a href="https://people.cs.vt.edu/~shaffer/Book/C++3e20100119.pdf">C++3e20100119.pdf</a>
		</li>
		<li>
			<a href="https://people.eecs.berkeley.edu/~vazirani/algorithms/chap3.pdf">chap3.pdf</a>
		</li>
		<li>
			<a href="https://people.eecs.berkeley.edu/~vazirani/algorithms/chap4.pdf">chap4.pdf</a>
		</li>
		<li>
			<a href="https://people.eecs.berkeley.edu/~vazirani/algorithms/chap5.pdf">chap5.pdf</a>
		</li>
		<li>
			<a href="https://www.cse.ust.hk/~dekai/271/notes/L14/L14.pdf">L14.dvi - L14.pdf</a>
		</li>
	</ul>
	<p>
		The discussion assignment was about breadth-first and depth-first searching, which is a very simple concept.
		So that was easy.
		That is, aside from the part that asked about greedy algorithms.
		As usual, I had to write up my post days before I had a day off to sit down and go through the material thoroughly.
		I didn&apos;t think there was a meaning for the term &quot;greedy&quot; in computer science other than the one I&apos;d already known, which is used in places such as greedy matching of regular expressions.
		It turns out that greediness in this context is an attempt to try the believed best solution first.
		So I got that wrong in the discussion assignment.
	</p>
	<p>
		The written assignment was easy this week as well; even more so because it was due later, so I actually had time to read the course material for the week before completing it.
		However, the assignment asked if the example graph was &quot;simple&quot;.
		The reading material didn&apos;t cover &quot;simple&quot; graphs, though one of the diagrams was labelled as one - it was never mentioned what simple graphs even are.
		Wikipedia came to the rescue when I tried a Web search, which surprised me.
		&quot;Simple&quot; is such a generic word that I would have thought I&apos;d need a lot more context to get any relevant information.
		I worry though about which graders I&apos;ll get.
		Some students mark you down for citing Wikipedia.
		It&apos;s ridiculous, seeing as a good many of the courses I&apos;ve taken here at this university have included Wikipedia pages <strong>*as a part of the reading assignments*</strong>.
		Clearly, this school does understand that Wikipedia is a decent source to learn from.
		But then, even in those classes, some students get weird when you try to cite the assigned reading material, just because that material was a part of Wikipedia.
		I get that some schools don&apos;t think Wikipedia is a reliable resource, but this school isn&apos;t one of them, so that shouldn&apos;t be held against those of us that make use of it.
	</p>
	<p>
		The concept of &quot;connected directional graphs&quot; is a bit oddly defined.
		If the connections are not bidirectional, they for some reason don&apos;t count.
		It&apos;s rather unintuitive.
		It&apos;s easy enough to understand, but it seems like maybe a more-accurate word than &quot;connected&quot; should have been used.
	</p>
	<p>
		The written assignment this week specifically said we don&apos;t have to work with actual code this week.
		It makes me wonder if we&apos;re going to be writing actual code for things like this in the future though.
		The data structure we built stored edges separately from vertices.
		That seems rather odd from a problem-solving perspective.
		When you&apos;re at a certain vertex, treating that vertex as a sort of node for the problem you&apos;re working with, you&apos;d then need to walk the entire list of edges to see which ones come from your current vertex.
		That doesn&apos;t seen efficient.
		Rather, you&apos;d want vertices with paths leading away from them to be parent nodes to the children the paths lead to.
		Or at the very least, you&apos;d want the nodes representing the vertices to contain a list of the nodes their paths lead to.
		I wonder what possible advantage this sort of representation could have.
		Serialisation, perhaps?
		Maybe you&apos;d have your application translate this into something more useful before using it, and translate back to this representation when storing it on disk.
	</p>
</section>
<section id="Unit4">
	<h2>Unit 4</h2>
	<p>
		The reading assignment for the week was as follows:
	</p>
	<ul>
		<li>
			<a href="https://en.wikipedia.org/wiki/Kruskal&apos;s_algorithm">Kruskal&apos;s algorithm - Wikipedia</a>
		</li>
		<li>
			Sections 11.1 through 11.3 of <a href="https://people.cs.vt.edu/~shaffer/Book/C++3e20100119.pdf">C++3e20100119.pdf</a>
		</li>
		<li>
			<a href="https://people.eecs.berkeley.edu/~vazirani/algorithms/chap4.pdf">chap4.pdf</a>
		</li>
		<li>
			<a href="https://www.cse.ust.hk/~dekai/271/notes/L07/L07.pdf">L07.dvi - L07.pdf</a>
		</li>
		<li>
			<a href="https://www.cse.ust.hk/~dekai/271/notes/L08/L08.pdf">L08.dvi - L08.pdf</a>
		</li>
	</ul>
	<p>
		Minimum cost spanning trees are an interesting concept.
		You cut down the cost of the graph by removing all technically-unnecessary connections.
		It reminds me a lot of a tunnel network I used to build in a game called Minetest.
		I used to tunnel out to everyone&apos;s various builds, connecting them with a flat, underground road, making it not only easy to walk to these distant places, but also easy to even <strong>*find*</strong> them.
		I was getting requests for tunnel exits so rapidly though that there was no way I could create the web of tunnels necessary to connect everywhere to everywhere else directly.
		There was too much of a backlog!
		Instead, I just connected each location to the nearest existing or future tunnel exit.
		I didn&apos;t do any formal analysis or anything, but basically, distance was my measure of cost and I attempted to connect all vertices (requested tunnel exits) while keeping that cost as low as possible.
		The road wasn&apos;t always as direct as would be desirable because of this though.
	</p>
	<p>
		That brings me to my other major thought on minimum spanning trees.
		I see very much why one would want to minimise costs by reducing the edges by creating one of these trees from a graph.
		However, I think we need to be careful about using these trees as well.
		Imagine if the real world road network were structured like my old tunnel network.
		Travel from one location to another would incur a high cost for travellers.
		There would be exactly one route to get from a given place to a given other place, and usually, it&apos;d require going several steps in the wrong direction for every step in the right direction.
		There are also other things to think of in many cases.
		For example, the one road connecting two places could suffer damage and need repair, or perhaps there&apos;s even just routine road maintenance.
		As another example, we have the Internet.
		Many places are connected and the connections are often quite fast.
		Having extra stops on the route might not even be noticeable by users, especially as with the reduced number of connections, the remaining connections and the routers themselves would be bolstered to handle the increased load.
		However, if any node or link become incapacitated, the network breaks into separate islands that can&apos;t speak to one another.
		We actually see that sort of thing in the <abbr title="Internet Relay Chat">IRC</abbr> protocol sometimes.
		We cal it a net split.
		Having redundant edges isn&apos;t always a bad thing, even if it&apos;s a bit more expensive.
	</p>
	<p>
		The quiz had a rather confusing question on it.
		It asked
	</p>
	<blockquote>
		<p>
			What is the big-o complexity of the purple line?
		</p>
	</blockquote>
	<p>
		That seems like a straightforward question.
		I mean, aside from the fact that absolutely no image was included, and there was no hint as to what purple line was even meant.
		Luckily, five questions down was another question, this time with a graphic:
	</p>
	<blockquote>
		<p>
			What is the big-o complexity of the green line?
		</p>
	</blockquote>
	<p>
		After another unrelated question, two more questions came up, both with the same graphic as the green line question:
	</p>
	<blockquote>
		<p>
			What is the big-o complexity of the red line?
		</p>
		<p>
			What is the big-o complexity of the blue line?
		</p>
	</blockquote>
	<p>
		I have to assume the purple line question was based on this same graph.
		Someone forgot to include the graphic in the question though, which is problematic because of the way these quizzes seem to work.
		As best I can tell from past quizzes, the questions seem to be randomised.
		That means that the purple line question could have come up without the graphic showing up anywhere on the quiz.
		Hopefully someone fixes that for next term.
	</p>
	<p>
		This month has been exhausting, and it&apos;s really starting to take its toll on me.
		The head manager has been out for the past two months, and the franchise owner has been intentionally under-staffing us to try to squeeze more profit out of us.
		I - along with one of the other shift leaders and one of the assistant managers - have been having to skip most of our breaks just to get everything done.
		It&apos;s been wearing me down.
		There&apos;s not been the energy left for school, and I&apos;ve been having to skim things a bit to stay on top of the work.
		Unfortunately, that led to a mistake this week.
		I mentioned last week that I wondered if we&apos;d be doing anything programmatically with that graph from last week&apos;s work.
		We did.
		We were supposed to implement Prim&apos;s algorithm to build a minimum spanning tree from it.
		However, I got the instructions wrong, and instead implemented Kruskal&apos;s algorithm.
		By the time I noticed, I didn&apos;t have time to go back and correct the error.
		I had to submit it as-is.
		That&apos;s how things go sometimes though.
	</p>
</section>
<section id="Unit5">
	<h2>Unit 5</h2>
	<p>
		The reading assignment for the week was as follows:
	</p>
	<ul>
		<li>
			Sections 16.1 through 16.2 of <a href="https://people.cs.vt.edu/~shaffer/Book/C++3e20100119.pdf">C++3e20100119.pdf</a>
		</li>
		<li>
			<a href="https://people.eecs.berkeley.edu/~vazirani/algorithms/chap6.pdf">chap6.pdf</a>
		</li>
		<li>
			<a href="http://videolectures.net/mit6046jf05_leiserson_lec15/">Lecture 15: Dynamic Programming, Longest Common Subsequence - VideoLectures.NET</a>
		</li>
	</ul>
	<p>
		As with last time we were assigned a video to watch on this website, the video won&apos;t play.
		It says it requires Adobe Flash, which of course, isn&apos;t something I can install on my system.
		It&apos;d be really nice if they provided a transcript.
		Even if the video relied on Web standards instead of Adobe Flash and was therefore able to play, a transcript would make it much easier to learn from.
		I learn much better by reading than by watching videos.
	</p>
	<p>
		The assignment instructions this week and last week have asked that we either use a Cloud9 instance or our own <abbr title="integrated development environment">IDE</abbr>s.
		I&apos;m not sure why Cloud9 was specifically mentioned separate from other <abbr title="integrated development environment">IDE</abbr>s.
		It&apos;s not like we have been given access to a Cloud9 instance for use with the class.
		I couldn&apos;t really find a public instance available either.
		I think last time I used a Java <abbr title="integrated development environment">IDE</abbr> for a course, I used Eclipse.
		Another time, I used NetBeans, I&apos;m pretty sure.
		However, neither of these <abbr title="integrated development environment">IDE</abbr>s are available in the Debian 10 repositories.
		I tried using Geany too, but Geany refuses to run Java code for some reason.
		It just keeps complaining that it can&apos;t find the class that shares a name with the file, even when it&apos;s the only class the file contains.
		I&apos;m really confused as to what the issue is.
		I&apos;ve been running my code in an online <abbr title="integrated development environment">IDE</abbr> before submitting it, so I know my code runs and does what I intend it to, but it&apos;s frustrating not to be able to run it locally for the time being.
	</p>
	<p>
		It seems that the solution to this week&apos;s assignment is supposed to find 45 valid knapsacks.
		I&apos;m confused as to where that number comes from.
		At first, I thought it to be the number of knapsack configurations that isn&apos;t over capacity.
		In other words, even if a knapsack is underpacked, it&apos;s count toward that number, but if it&apos;s overpacked and cannot be carried, it doesn&apos;t count toward it.
		However, my code solution found 3571 of such configurations.
		So I figured this was the number of knapsacks that solved the problem.
		In other words, those that were packed the best.
		I rewrote my code to count those instead.
		However, my code solution found only two of such configurations.
		I&apos;m not sure where the number 45 comes in.
		To top it off, the best solution found by my code matched the example weight and example value perfectly.
		That means my code didn&apos;t fail to find the correct solution(s).
		If my code failed to find the correct solution, I could at least expect the accompanying statistics to turn out wrong.
	</p>
	<p>
		One of the students I graded work for this week came up with some interesting code.
		In my code, I encoded edges as a list of pairs of vertices along with weights.
		That allowed every edge to be represented and nothing that wasn&apos;t an edge to be represented.
		This student instead used a two-dimensional array with the first dimension being the points lead from and the second being the points led to.
		All vertices then had an edge connecting them represented in the data structure.
		Any non-existent edge was given the value 999, a value so much higher than any real edge that it&apos;d never be chosen as an edge to keep in the tree.
		It required a bunch of this filler data to be stored, but in exchange, it allowed the representation of references to valid edges to be made quite a bit more intuitive.
	</p>
	<p>
		Another student added a bunch of headers and footers to their work, even in the middle of their code segment.
		It made running the code fail, as the headers and footers were interpreted by the <abbr title="integrated development environment">IDE</abbr> to be malformed code.
		I&apos;m not sure why people think they have to up upload attached word processing documents containing code instead of simply pasting their code into the submission form, which would make it easy to copy the code and easy to submit it even.
		It&apos;s annoying to have to download the attacked files, open them, then copy the code.
		Or at the very least, they could try uploading <code>.java</code> files.
		That&apos;d at least make sense.
		But to additionally break up the code with inserted headers and footers so even copying and pasting the code into a <code>.java</code> file doesn&apos;t let the code run?
		I&apos;m really not sure what they were thinking.
	</p>
</section>
<section id="Unit6">
	<h2>Unit 6</h2>
	<p>
		...
	</p>
</section>
<section id="Unit7">
	<h2>Unit 7</h2>
	<p>
		...
	</p>
</section>
<section id="Unit8">
	<h2>Unit 8</h2>
	<p>
		...
	</p>
</section>
		<hr/>
		<p>
			Copyright © 2020 Alex Yst;
			You may modify and/or redistribute this document under the terms of the <a rel="license" href="/license/gpl-3.0-standalone.xhtml"><abbr title="GNU&apos;s Not Unix">GNU</abbr> <abbr title="General Public License version Three or later">GPLv3+</abbr></a>.
			If for some reason you would prefer to modify and/or distribute this document under other free copyleft terms, please ask me via email.
			My address is in the source comments near the top of this document.
			This license also applies to embedded content such as images.
			For more information on that, see <a href="/en/a/licensing.xhtml">licensing</a>.
		</p>
		<p>
			<abbr title="World Wide Web Consortium">W3C</abbr> standards are important.
			This document conforms to the <a href="https://validator.w3.org./nu/?doc=https%3A%2F%2Fy.st.%2F%5BTEMP%5D%2F%5BTEMP%5D.xhtml"><abbr title="Extensible Hypertext Markup Language">XHTML</abbr> 5.2</a> specification and uses style sheets that conform to the <a href="http://jigsaw.w3.org./css-validator/validator?uri=https%3A%2F%2Fy.st.%2F%5BTEMP%5D%2F%5BTEMP%5D.xhtml"><abbr title="Cascading Style Sheets">CSS</abbr>3</a> specification.
		</p>
	</body>
</html>

